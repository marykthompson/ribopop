{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize probe results\n",
    "- Analyze individual qPCR plate data with the output and the template, return ddCt averages from technical reps\n",
    "- Combine into entire experiment df, get fold change and std fold change of the three replicates\n",
    "- Combine the qPCR data with probe thermodynamic properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gffutils\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from Bio import SeqIO\n",
    "import HTSeq\n",
    "import primer3\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n",
    "import primer3\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "sys.path.append('../scripts/')\n",
    "from plot_helpers import *\n",
    "import analyze_qpcr_plate\n",
    "sys.path.append(os.path.join(probe_designer_dir, 'scripts'))\n",
    "import screen_kmers\n",
    "import choose_probes\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I: Summarize the qPCR depletion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = '../figures/F1/'\n",
    "os.makedirs(outdir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qpcr_dir = os.path.join(results_dir, 'qPCR_data')\n",
    "\n",
    "data = [\n",
    "'190417_rep1_A/20190417_171207_CT003077__QPCRBIOSMALQuantificationPlateViewResults.xlsx', \n",
    "'190418_rep2_A/20190418_154147_CT003077__QPCRBIOSMALQuantificationPlateViewResults.xlsx', \n",
    "'190425_rep3_A/20190425_152906_CT003077__QPCRBIOSMALQuantificationPlateViewResults.xlsx',   \n",
    "'190418_rep1_B/20190418_165533_CT003077__QPCRBIOSMALQuantificationPlateViewResults.xlsx', \n",
    "'190419_rep2_B/20190419_130040_CT003077__QPCRBIOSMALQuantificationPlateViewResults.xlsx',\n",
    "'190426_rep3_B/20190426_125032_CT003077__QPCRBIOSMALQuantificationPlateViewResults.xlsx',\n",
    "'190422_rep1_C/20190422_143153_CT003077__QPCRBIOSMALQuantificationPlateViewResults.xlsx',\n",
    "'190419_rep2_C/20190419_153322_CT003077__QPCRBIOSMALQuantificationPlateViewResults.xlsx', \n",
    "'190422_rep3_C/20190422_161800_CT003077__QPCRBIOSMALQuantificationPlateViewResults.xlsx',  \n",
    "'190625_rep1_D/20190625_133705_CT003077__QPCRBIOSMALQuantificationPlateViewResults.xlsx',\n",
    "'190626_rep2_D/20190626_134856_CT003077__QPCRBIOSMALQuantificationPlateViewResults.xlsx',\n",
    "'190628_rep3_D/20190628_125833_CT003077__QPCRBIOSMALQuantificationPlateViewResults.xlsx'\n",
    "]\n",
    "\n",
    "templates = [\n",
    "'190417_rep1_A/qPCR_analysis_template_rep1_A.xlsx', \n",
    "'190418_rep2_A/qPCR_analysis_template_rep2_A.xlsx', \n",
    "'190425_rep3_A/qPCR_analysis_template_rep3_A.xlsx',\n",
    "'190418_rep1_B/qPCR_analysis_template_rep1_B.xlsx', \n",
    "'190419_rep2_B/qPCR_analysis_template_rep2_B.xlsx', \n",
    "'190426_rep3_B/qPCR_analysis_template_rep3_B.xlsx',\n",
    "'190422_rep1_C/qPCR_analysis_template_rep1_C.xlsx', \n",
    "'190419_rep2_C/qPCR_analysis_template_rep2_C.xlsx',\n",
    "'190422_rep3_C/qPCR_analysis_template_rep3_C.xlsx',\n",
    "'190625_rep1_D/qPCR_analysis_template_rep1_D.xlsx',\n",
    "'190626_rep2_D/qPCR_analysis_template_rep2_D.xlsx',\n",
    "'190628_rep3_D/qPCR_analysis_template_rep3_D.xlsx'\n",
    "]\n",
    "\n",
    "exps = {'data': [os.path.join(qpcr_dir, i) for i in data],\n",
    "       'templates': [os.path.join(qpcr_dir, i) for i in templates]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the probe sequences, and add to the df\n",
    "probe_seqs = os.path.join(qpcr_dir, 'probe_seqs.csv')\n",
    "seq_df = pd.read_csv(probe_seqs, index_col = 'probe_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the data from each replicate\n",
    "#https://stackoverflow.com/questions/19078325/naming-returned-columns-in-pandas-aggregate-function\n",
    "long_probe_ids = ['D2', 'D6', 'D13', 'D17', 'D19']\n",
    "df_list = []\n",
    "for i in range(0, len(exps['data'])):\n",
    "    #For set D, remove B2 and B15 because these were included as plate controls\n",
    "    if i > 8:\n",
    "        df_list.append(analyze_qpcr_plate.main(exps['data'][i], exps['templates'][i], 'act5c', drop_samples = ['B2', 'B15']))\n",
    "    else:\n",
    "        df_list.append(analyze_qpcr_plate.main(exps['data'][i], exps['templates'][i], 'act5c'))\n",
    "df = pd.concat(df_list)\n",
    "qpcr_df = df.groupby(['primer', 'sample']).agg(mean_frac_remaining = ('fold_change', np.mean), std_frac_remaining = ('fold_change', np.std))\n",
    "qpcr_df.index.rename('probe_name', level = 'sample', inplace = True)\n",
    "qpcr_df = qpcr_df.loc[qpcr_df.index.get_level_values('probe_name').map(lambda x: (x.startswith('B') or x in long_probe_ids))].copy()\n",
    "#Retain all the values, including the ddCt values, for stats later\n",
    "full_df = df.loc[df.index.get_level_values('sample').map(lambda x: (x.startswith('B') or x in long_probe_ids))].copy()\n",
    "full_df_num = pd.merge(full_df.reset_index('sample', drop = False), seq_df[['probe_num']], left_on = 'sample', right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the Tm, sequence, and structure values to the set of tested 18S probes\n",
    "#merge on name, but then switch to using probe number\n",
    "probe_18S_df = pd.merge(qpcr_df, seq_df[['probe_num', 'sequence']], left_index = True, right_index = True, how = 'right')\n",
    "probe_18S_df['length'] = probe_18S_df['sequence'].apply(lambda x: len(x))\n",
    "probe_18S_df['target_seq'] = probe_18S_df['sequence'].apply(lambda x: Seq(x).reverse_complement())\n",
    "probe_18S_df['Tm'] = probe_18S_df['target_seq'].apply(lambda x: mt.Tm_NN(x.transcribe(), nn_table = mt.R_DNA_NN1, Na = 300, saltcorr = 4, dnac1 = 250, dnac2 = 0))\n",
    "\n",
    "#to get the params for any probes, even those that did not pass filters, for analysis\n",
    "default_rules = ['GC_content_rule', '4xA_stack_rule', '4xC_stack_rule', 'any5_rule']\n",
    "probe_18S_df = screen_kmers.sequence_composition_filter(probe_18S_df, 0.4, 0.6, default_rules, filter = False)\n",
    "probe_18S_df = screen_kmers.structure_filter(probe_18S_df, -3, -10, 300, filter = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Annotate id labels with categories\n",
    "pool1_ids = range(1, 21)\n",
    "pool2_ids = range(21, 31)\n",
    "long_ids = range(31, 36)\n",
    "lowtm_pool1_ids = range(1, 12)\n",
    "\n",
    "probe_18S_df['length_category'] = probe_18S_df['probe_num'].map(lambda x: '~50mer' if x in long_ids else '~30mer')\n",
    "probe_18S_df['tm_category'] = probe_18S_df['probe_num'].map(lambda x: 'high Tm' if x in pool2_ids else ('low Tm' if x in lowtm_pool1_ids else np.nan))\n",
    "\n",
    "#write the table with the ddCt values\n",
    "full_df_num['length_category'] = full_df_num['probe_num'].map(lambda x: '~50mer' if x in long_ids else '~30mer')\n",
    "full_df_num['tm_category'] = full_df_num['probe_num'].map(lambda x: 'high Tm' if x in pool2_ids else ('low Tm' if x in lowtm_pool1_ids else np.nan))\n",
    "full_df_num.to_csv(os.path.join(outdir, 'full_probe_18S_summary.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II: Use the sequences to annotate the target positions on the 18S and calculate thermodynamic metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the rRNA metrics for mapping the probes to the sequence\n",
    "#Mapping to check the position is necessary because the PDB-derived sequences have some indels relative to the consensus\n",
    "struct_18S = os.path.join(results_dir,'other_data/structure_18S_frompdb.fasta')\n",
    "struct_28S = os.path.join(results_dir,'other_data/structure_28S_frompdb.fasta')\n",
    "\n",
    "cons_18S = os.path.join(results_dir, 'probe_design_results/dmel_200504/target_sequences/consensus/18S.fa')\n",
    "cons_28S = os.path.join(results_dir, 'probe_design_results/dmel_200504/target_sequences/consensus/28S.fa')\n",
    "\n",
    "fasta_dict = {'struct_small': struct_18S, 'struct_large': struct_28S, 'cons_small': cons_18S, 'cons_large': cons_28S}\n",
    "\n",
    "struct_outdir = os.path.join(outdir, 'data_structure_mapping')\n",
    "os.makedirs(struct_outdir, exist_ok = True)\n",
    "to_build = ['struct_small', 'cons_small']\n",
    "\n",
    "for i in to_build:\n",
    "    fasta_file = os.path.join(struct_outdir, '%s.fasta' % i)\n",
    "    this_seq = next(SeqIO.parse(fasta_dict[i], \"fasta\"))\n",
    "    this_seq.seq = this_seq.seq.back_transcribe()\n",
    "    SeqIO.write(this_seq, fasta_file, \"fasta\")\n",
    "    subprocess.run(['bowtie2-build', fasta_file, os.path.join(struct_outdir, i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Align with bowtie to the consensus sequence or the structural sequence\n",
    "probe_string = ','.join(probe_18S_df.reset_index()[['probe_num', 'sequence']].sort_values('probe_num')['sequence'].values)\n",
    "to_align = ['struct_small', 'cons_small']\n",
    "\n",
    "seed_len = 8\n",
    "for i in to_align:\n",
    "    index_base = os.path.join(struct_outdir, i)\n",
    "    sam_outfile = os.path.join(struct_outdir, '%s_aligned_seqs.sam' % i)\n",
    "    subprocess.run(['bowtie2', '-x', index_base, '-c', probe_string, '-L', str(seed_len), '-S', sam_outfile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse the alignment files and add the consensus sequence or structural sequence indices (convert to 1-based)\n",
    "def add_aln_pos(sam_file, start_name, end_name):\n",
    "    pos_dict = {}\n",
    "    sam_reader = HTSeq.SAM_Reader(sam_file)\n",
    "    for aln in sam_reader:\n",
    "        if aln.aligned:\n",
    "            #convert positions back to 1-based, end inclusive for pymol\n",
    "            probe_num = int(aln.read.name) + 1\n",
    "            pos_dict[probe_num] = {}\n",
    "            pos_dict[probe_num][start_name] = aln.iv.start + 1\n",
    "            pos_dict[probe_num][end_name] = aln.iv.end\n",
    "            \n",
    "    pos_df = pd.DataFrame.from_dict(pos_dict, orient = 'index')\n",
    "    return pos_df\n",
    "\n",
    "cons_aln = os.path.join(struct_outdir, '%s_aligned_seqs.sam' % 'cons_small')\n",
    "struc_aln = os.path.join(struct_outdir, '%s_aligned_seqs.sam' % 'struct_small')\n",
    "cons_df = add_aln_pos(cons_aln, 'consensus_start', 'consensus_end')\n",
    "probe_18S_df = pd.merge(probe_18S_df, cons_df, left_on = 'probe_num', right_index = True)\n",
    "struct_df = add_aln_pos(cons_aln, 'structure_start', 'structure_end')\n",
    "probe_18S_df = pd.merge(probe_18S_df, struct_df, left_on = 'probe_num', right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write table S1\n",
    "cols = ['probe_num', 'probe_name', 'mean_frac_remaining', 'std_frac_remaining', 'consensus_start', 'consensus_end', 'structure_start', 'structure_end', 'sequence', 'length', 'Tm', 'GC_content', 'hairpin_dG', 'homodimer_dG']\n",
    "probe_18S_df.reset_index().sort_values(by = 'probe_num')[cols].to_csv(os.path.join(outdir, 'TableS1_18S_candidate_properties.csv'), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
